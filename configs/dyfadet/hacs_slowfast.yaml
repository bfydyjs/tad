pad_len: &pad_len 960

dataset:
  common: &dataset_common
    type: "AnetPaddingDataset"
    ann_file: "data/hacs-1.1.1/annotations/HACS_segments_v1.1.1.json"
    block_list: "data/hacs-1.1.1/features/slowfast101_15fps_stride8_len32_hacs/missing_files.txt"
    class_map: "data/hacs-1.1.1/annotations/category_idx.txt"
    data_path: "data/hacs-1.1.1/features/slowfast101_15fps_stride8_len32_hacs/"
    feature_stride: 8
    sample_stride: 1
    offset_frames: 16
    fps: 15
  train:
    <<: *dataset_common
    subset_name: training
    filter_gt: true
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: ["feats", "gt_segments", "gt_labels"]
      - type: RandomTrunc
        trunc_len: *pad_len
        trunc_thresh: 0.5
        crop_ratio: [0.9, 1.0]
      - type: Rearrange
        keys: ["feats"]
        ops: "t c-> c t"
      - type: Collect
        inputs: "feats"
        keys: ["masks", "gt_segments", "gt_labels"]
  val:
    <<: *dataset_common
    subset_name: validation
    filter_gt: false
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: ["feats", "gt_segments", "gt_labels"]
      - type: Padding
        length: *pad_len
      - type: Rearrange
        keys: ["feats"]
        ops: "t c-> c t"
      - type: Collect
        inputs: "feats"
        keys: ["masks", "gt_segments", "gt_labels"]
  test:
    <<: *dataset_common
    subset_name: validation
    filter_gt: false
    test_mode: true
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: ["feats"]
      - type: Padding
        length: *pad_len
      - type: Rearrange
        keys: ["feats"]
        ops: "t c-> c t"
      - type: Collect
        inputs: "feats"
        keys: ["masks"]

evaluation:
  type: mAP
  subset: validation
  tiou_thresholds: [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
  ground_truth_filename: annotation_path

model:
  type: DyFADet
  projection:
    type: DynEProj
    in_channels: 2304
    out_channels: 1024
    arch: [2, 2, 5]
    use_abs_pe: true
    max_seq_len: *pad_len
    mlp_dim: 1024
    encoder_win_size: 3
    k: 1.2
    init_conv_vars: 0.1
    path_pdrop: 0.1
    input_noise: 0.2
  neck:
    type: FPNIdentity
    in_channels: 1024
    out_channels: 1024
    num_levels: 6
  rpn_head:
    type: TDynHead
    num_classes: 200
    in_channels: 1024
    feat_channels: 1024
    num_convs: 2
    head_kernel_size: 5
    dyn_head_cfg:
      tau: 1.5
      init_gate: 1.0
      type: GeReTanH
      dyn_type: c
    cls_prior_prob: 0.01
    prior_generator:
      type: PointGenerator
      strides: [1, 2, 4, 8, 16, 32]
      regression_range: [[0, 4], [4, 8], [8, 16], [16, 32], [32, 64], [64, 10000]]
    loss_normalizer: 400
    loss_normalizer_momentum: 0.9
    center_sample: radius
    center_sample_radius: 1.5
    label_smoothing: 0.1
    loss:
      cls_loss:
        type: FocalLoss
      reg_loss:
        type: DIOULoss

solver:
  train:
    batch_size: 8
    num_workers: 4
  val:
    batch_size: 8
    num_workers: 4
  test:
    batch_size: 8
    num_workers: 4
  clip_grad_norm: 0.5

optimizer:
  type: AdamW
  lr: 0.0005
  weight_decay: 0.025
  paramwise: true

scheduler:
  type: LinearWarmupCosineAnnealingLR
  warmup_epoch: 7
  max_epoch: 14
  eta_min: 0.0005

inference:
  load_from_raw_predictions: false
  save_raw_prediction: false

post_processing:
  nms:
    use_soft_nms: true
    sigma: 0.75
    max_seg_num: 250
    min_score: 0.001
    multiclass: false
    voting_thresh: 0.95
  external_cls:
    type: TCANetHACSClassifier
    path: data/hacs-1.1.1/classifiers/validation94.32.json
    topk: 3
  save_dict: false

workflow:
  logging_interval: 200
  checkpoint_interval: 1
  
  val_eval_interval: 1
  val_start_epoch: 10

work_dir: exps/hacs/dyfadet_slowfast