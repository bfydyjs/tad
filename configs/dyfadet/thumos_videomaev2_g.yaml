dataset:
  common: &default_common
    type: "ThumosPaddingDataset"
    ann_file: "data/thumos-14/annotations/thumos_14_anno.json"
    block_list: "data/thumos-14/features/i3d_actionformer_stride4_thumos/missing_files.txt"
    class_map: "data/thumos-14/annotations/category_idx.txt"
    data_path: "data/thumos-14/features/videomaev2-giant_k710_16x4x1_img224_stride4_len16_interval1_thumos/"
    feature_stride: 4
    sample_stride: 1
    offset_frames: 2

  train:
    <<: *default_common
    subset_name: "training"
    filter_gt: false
    pipeline:
      - type: "LoadFeats"
        feat_format: "npy"
      - type: "ConvertToTensor"
        keys: ["feats", "gt_segments", "gt_labels"]
      - type: "RandomTrunc"
        trunc_len: 2304
        trunc_thresh: 0.5
        crop_ratio: [0.9, 1.0]
      - type: "Rearrange"
        keys: ["feats"]
        ops: "t c -> c t"
      - type: "Collect"
        inputs: "feats"
        keys: ["masks", "gt_segments", "gt_labels"]

  val:
    <<: *default_common
    subset_name: "validation"
    filter_gt: false
    pipeline:
      - type: "LoadFeats"
        feat_format: "npy"
      - type: "ConvertToTensor"
        keys: ["feats", "gt_segments", "gt_labels"]
      - type: "Rearrange"
        keys: ["feats"]
        ops: "t c -> c t"
      - type: "Collect"
        inputs: "feats"
        keys: ["masks", "gt_segments", "gt_labels"]

  test:
    <<: *default_common
    subset_name: "validation"
    filter_gt: false
    test_mode: true
    pipeline:
      - type: "LoadFeats"
        feat_format: "npy"
      - type: "ConvertToTensor"
        keys: ["feats"]
      - type: "Rearrange"
        keys: ["feats"]
        ops: "t c -> c t"
      - type: "Collect"
        inputs: "feats"
        keys: ["masks"]

evaluation:
  type: "mAP"
  subset: "validation"
  tiou_thresholds: [0.3, 0.4, 0.5, 0.6, 0.7]
  ground_truth_filename: "data/thumos-14/annotations/thumos_14_anno.json"

model:
  type: "DyFADet"
  projection:
    type: "DynEProj"
    in_channels: 1408
    out_channels: 512
    arch: [2, 2, 5]  # layers in embed / stem / branch
    use_abs_pe: false
    max_seq_len: 2304
    mlp_dim: 768
    encoder_win_size: 1
    k: 5
    init_conv_vars: 0
    path_pdrop: 0.005
    input_noise: 1.0e-5
  neck:
    type: "FPNIdentity"
    in_channels: 512
    out_channels: 512
    num_levels: 6
  rpn_head:
    type: "TDynHead"
    num_classes: 20
    in_channels: 512
    feat_channels: 512
    num_convs: 2
    head_kernel_size: 3
    dyn_head_cfg:
      tau: 1.5
      init_gate: 1.0
      type: "GeReTanH"
      dyn_type: "c"
    cls_prior_prob: 0.01
    prior_generator:
      type: "PointGenerator"
      strides: [1, 2, 4, 8, 16, 32]
      regression_range: [[0, 4], [4, 8], [8, 16], [16, 32], [32, 64], [64, 10000]]
    loss_normalizer: 100
    loss_normalizer_momentum: 0.9
    center_sample: "radius"
    center_sample_radius: 1.5
    label_smoothing: 0.0
    loss:
      cls_loss:
        type: "FocalLoss"
      reg_loss:
        type: "DIOULoss"

solver:
  train:
    batch_size: 2
    num_workers: 2
  val:
    batch_size: 1
    num_workers: 1
  test:
    batch_size: 1
    num_workers: 1
  clip_grad_norm: 1

optimizer:
  type: "AdamW"
  lr: 1.0e-4
  weight_decay: 0.025
  paramwise: true

scheduler:
  type: "LinearWarmupCosineAnnealingLR"
  warmup_epoch: 20
  max_epoch: 60

inference:
  load_from_raw_predictions: false
  save_raw_prediction: false

post_processing:
  nms:
    use_soft_nms: true
    sigma: 0.5
    max_seg_num: 2000
    min_score: 0.001
    multiclass: true
    voting_thresh: 0.7
  save_dict: false

workflow:
  logging_interval: 20
  checkpoint_interval: 1
  
  val_eval_interval: 1
  val_start_epoch: 30
  end_epoch: 45

work_dir: "exps/thumos/dyfadet_videomaev2_g"