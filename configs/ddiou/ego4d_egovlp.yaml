dataset:
  common: &dataset_common
    type: Ego4DSlidingDataset
    ann_file: data/ego4d/annotations/ego4d_v2_220429.json
    class_map: data/ego4d/annotations/category_idx.txt
    data_path: data/ego4d/features/mq_egovlp/
    block_list: null
    feature_stride: 16
    sample_stride: 1
    offset_frames: 8
  train:
    <<: *dataset_common
    type: Ego4DPaddingDataset
    subset_name: train
    filter_gt: false
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: [feats, gt_segments, gt_labels]
      - type: RandomTrunc
        trunc_len: 1024
        trunc_thresh: 0.3
        crop_ratio: [0.9, 1.0]
      - type: Rearrange
        keys: [feats]
        ops: t c -> c t
      - type: Collect
        inputs: feats
        keys: [masks, gt_segments, gt_labels]
  val:
    <<: *dataset_common
    subset_name: val
    filter_gt: false
    # dataloader setting
    window_size: 1024
    window_overlap_ratio: 0
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: [feats, gt_segments, gt_labels]
      - type: SlidingWindowTrunc
        with_mask: true
      - type: Rearrange
        keys: [feats]
        ops: t c -> c t
      - type: Collect
        inputs: feats
        keys: [masks, gt_segments, gt_labels]
  test:
    <<: *dataset_common
    subset_name: val
    filter_gt: false
    test_mode: true
    # dataloader setting
    window_size: 1024
    window_overlap_ratio: 0
    pipeline:
      - type: LoadFeats
        feat_format: npy
      - type: ConvertToTensor
        keys: [feats]
      - type: SlidingWindowTrunc
        with_mask: true
      - type: Rearrange
        keys: [feats]
        ops: t c -> c t
      - type: Collect
        inputs: feats
        keys: [masks]

evaluation:
  type: mAP
  subset: val
  tiou_thresholds: [0.1, 0.2, 0.3, 0.4, 0.5]
  ground_truth_filename: data/ego4d/annotations/ego4d_v2_220429.json
  top_k: [1, 5]

model:
  type: DyFADet
  projection:
    type: DynEProj
    in_channels: 256
    out_channels: 384
    arch: [2, 2, 8]  # layers in embed / stem / branch
    use_abs_pe: true
    max_seq_len: 2304
    mlp_dim: 1024
    encoder_win_size: 9
    k: 5
    init_conv_vars: 0
    path_pdrop: 0.005
    input_noise: 1.0e-5
  neck:
    type: FPNIdentity
    in_channels: 384
    out_channels: 384
    num_levels: 9
  rpn_head:
    type: DecoupledIoUHead
    num_classes: 110
    in_channels: 384
    feat_channels: 384
    num_convs: 3
    iou_loss_weight: 1.0
    cls_prior_prob: 0.01
    prior_generator:
      type: PointGenerator
      strides: [1, 2, 4, 8, 16, 32, 64, 128, 256]
      regression_range: [[0, 4], [2, 8], [4, 16], [8, 32], [16, 64], [32, 128], [64, 256], [128, 512], [256, 10000]]
    loss_normalizer: 100
    loss_normalizer_momentum: 0.9
    center_sample: radius
    center_sample_radius: 1.5
    label_smoothing: 0.0
    loss:
      cls_loss:
        type: FocalLoss
      reg_loss:
        type: DIOULoss

solver:
  train:
    batch_size: 2
    num_workers: 1
  val:
    batch_size: 2
    num_workers: 1
  test:
    batch_size: 2
    num_workers: 1
  clip_grad_norm: 1

optimizer:
  lr: 1.0e-4
  weight_decay: 0.05
  paramwise: true

scheduler:
  warmup_epoch: 20
  max_epoch: 45

inference:
  load_from_raw_predictions: false
  save_raw_prediction: false

post_processing:
  nms:
    use_soft_nms: true
    sigma: 0.5
    max_seg_num: 2000
    min_score: 0.001
    multiclass: true
    voting_thresh: 0.7
  save_dict: false

workflow:
  logging_interval: 100
  checkpoint_interval: 1
  val_eval_interval: 1
  val_start_epoch: 30

work_dir: exps/ego4d/ddiou_egovlp